{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 540 Final Project\n",
    "\n",
    "#### Estimation of network reliability probability by Monte Carlo Simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network reliability is a provident field by the development of the AI and the Internet, A signal sent from A to B in the network must follow a path along any available edges.\n",
    "\n",
    "Impertinent network reliability means that the signal may fail to be transmitted correctly.\n",
    "\n",
    "This project will focus on the computation of network failure probability ,which can evaluate the network reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method: Evaluate the probability of network failure given specific probabilities for the failure of each edge.\n",
    "Assumption: Consider the simplest case: each edge is assumed to fail independently with the same probability with P.\n",
    "\n",
    "\n",
    "Generate the samples:$\\vec{x}=\\left(x_{1}, x_{2} \\ldots x_{20}\\right)$,where $x_{i}'s$ ~ independent Bernouli Distribution\n",
    "\n",
    "then the Bernouli random vector is:\n",
    "\n",
    "$$h(\\vec{x})=\\left\\{\\begin{array}{l}0, \\text { if } A \\text { and } B \\text { are connected (working)} \\\\ 1, \\text { if } A \\text { and } B \\text { are not connected (failure) }\\end{array}\\right.$$\n",
    "\n",
    "\n",
    "Then, the probability of network failure is:\n",
    "\n",
    "\n",
    "$$E[h(\\vec{x})]=\\mu$$\n",
    "\n",
    "\n",
    "However, Calculating the $\\mu$ of any network in realistic size can be a very difficult combinational problem. \n",
    "\n",
    "So we introduced the `Monte Carlo simulation` to solve the problem.\n",
    "\n",
    "the first method is Monte Carlo Integration, and the second is Impotance sampling method:\n",
    "\n",
    "\n",
    "1. Monte Carlo Integration:\n",
    "$\\hat{u}_{M c}=\\frac{1}{n} \\sum_{i=1}^{n} h\\left(\\vec{x}_{i}\\right)$\n",
    "\n",
    "2.Impotance Sampling:\n",
    "$\\hat{\\mu}_{I S}=\\frac{1}{n} \\sum_{i=1}^{n} w\\left(\\vec{x}_{i}^{*}\\right) h\\left(\\vec{x}_{i}^{*}\\right)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Draw the network graph\n",
    "\n",
    "#### Assuming that the network is `undirected`, each edge has the same `weight` and `capacity`.\n",
    "\n",
    "Since we would like to study the network failure from the beginning, we need these assuption, and the results did tell us we can have a lot work to do in the future.\n",
    "\n",
    "The network graph we create was from the lecture 540:540 computational methods.The network faliure is related to the minimal cut of the network.So our first target is to find the minimal cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-30b6d6a0b5c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gn = nx.Graph()\n",
    "\n",
    "edges_list = [('A', '1'), ('A', '2'), ('A', '3'), ('A', '4'), ('1', '2'), ('1', '5'), ('1', '6'), ('2', '6'), ('2', '3'), ('3', '7'), ('3', '4'), ('4', '7'), ('4', '8'), ('5', '6'), ('5', 'B'), ('6', '7'), ('6', 'B'), ('7', '8'), ('7', 'B'), ('8', 'B')]\n",
    "\n",
    "pos = {'A':(-2,0), '1':(-1,1.5), '2':(-1,0.5),  '3':(-1,-0.5),  '4':(-1,-1.5),\n",
    "        '5':(0,1.5), '6': (0,0.5), '7':(0,-0.5),  '8':(0,-1.5), 'B':(1,-0),}\n",
    "\n",
    "Gn.add_edges_from(edges_list, weight=1,capacity=1) #Assuming the network is undirected, each edge has the same weight and capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "nx.draw(Gn, pos= pos,with_labels=True,node_size=500,node_color='yellow')\n",
    "\n",
    "# labeling the edges\n",
    "nx.draw_networkx_edge_labels(Gn,pos,edge_labels={('A','1'):'$X_1$', ('A', '2'):'$X_2$',('A', '3'):\"$X_3$\", ('A', '4'):\"$X_4$\",('1', '2'):\"$X_5$\", ('1', '5'):\"$X_8$\", ('1', '6'):\"$X_9$\", ('2', '6'):\"$X_{10}$\", ('2', '3'):\"$X_{6}$\", ('3', '7'):\"$X_{11}$\", ('3', '4'):\"$X_{7}$\", ('4', '7'):\"$X_{12}$\", ('4', '8'):\"$X_{13}$\", ('5', '6'):\"$X_{14}$\", ('5', 'B'):\"$X_{17}$\", ('6', '7'):\"$X_{15}$\", ('6', 'B'):\"$X_{18}$\", ('7', '8'):\"$X_{16}$\", ('7', 'B'):\"$X_{19}$\", ('8', 'B'):\"$X_{20}$\"} ,font_size=20,font_color='red')\n",
    "\n",
    "# plt.savefig(\"Evaluation of network reliability.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Find the minimal cut of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_value, partition = nx.minimum_cut(Gn,  \"A\", \"B\")\n",
    "reachable, non_reachable = partition\n",
    "\n",
    "cutset = set()\n",
    "for u, nbrs in ((n, Gn[n]) for n in reachable):\n",
    "    cutset.update((u, v) for v in nbrs if v in non_reachable)\n",
    "print(f\"The minimal cut is\",sorted(cutset),\"the cut set is \",partition)\n",
    "\n",
    "# cut_value == sum(Gn.edges[u, v][\"capacity\"] for (u, v) in cutset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we find the minimal cut of this network, the edges are $X_{17}$ ~ $X_{20}$,which means if the four edges is not working as the same time, the network will fail, the signal will not be transmitted from A to B.Next we will calculted the failure probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Generate the bernoulli random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 20-dimension bernoulli verctor\n",
    "np.random.seed(seed=540)\n",
    "\n",
    "N=100000\n",
    "p = 0.1\n",
    "n=20\n",
    "\n",
    "bernoulli_rvs=bernoulli.rvs(size=N * n,p=p)\n",
    "data=np.reshape(np.mat(bernoulli_rvs),(N,n))\n",
    "\n",
    "h_x =pd.DataFrame(data)\n",
    "h_x.head() # samples generated from the bernouli distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 calculate the failure probability of each edge using monte carlo integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_edge_fail = h_x.sum() / N #monte carlo integration\n",
    "p_edge_fail #the failure probability of each edge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The failure probability of edge $X_{17}$ ~ $X_{20}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_17 = p_edge_fail[16]\n",
    "p_18 = p_edge_fail[17]\n",
    "p_19 = p_edge_fail[18]\n",
    "p_20 = p_edge_fail[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_fail_MCI = round(p_17 * p_18 * p_19 * p_20,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the network failure probability is {P_fail_MCI} by the monte carlo integration method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see when the failure probability of each edge is small, the $h(\\vec{x}) $  rarely reaches 1.So a large amount of simulations should be performed to estimate the u with sufficient  precision. To be more accurate , we need the IS sampling, to improve the integral approximation: use importance sampling approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we generate the bernouli random samples $\\vec{x}=\\left(x_{1}, x_{2} \\ldots x_{20}\\right)$. Now with the Importance samplling method, we need to generate bernouli random samples $\\vec{x}_{1}^{*}, \\vec{x}_{2}^{*}, \\ldots, \\vec{x}_{n}^{*}$ from $ g(\\vec{x})=g\\left(x_{1}, x_{2} \\cdots, x_{20}\\right)$ ,where $\\left.x_{i} \\text { ~Bernouli }\\left(p^{*}\\right) \\text { where } p^{*}\\right \\rangle p$\n",
    "\n",
    "$g(\\vec{x})$ is the proposal function in the Importance samplling approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 generate bernouli random samples $\\vec{x}_{1}^{*}, \\vec{x}_{2}^{*}, \\ldots, \\vec{x}_{n}^{*}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "\n",
    "p_star = 0.2 #p_star should be greater than p\n",
    "n=20\n",
    "\n",
    "bernoulli_rvs_star=bernoulli.rvs(size=N * n,p=p_star)\n",
    "data_star =np.reshape(np.mat(bernoulli_rvs_star),(N,n))\n",
    "\n",
    "h_x_star =pd.DataFrame(data_star)\n",
    "h_x_star.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_faill = h_x_star.T.sum()\n",
    "n_faill.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_17 = h_x_star[16]\n",
    "x_18 = h_x_star[17]\n",
    "x_19 = h_x_star[18]\n",
    "x_20 = h_x_star[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# h_x_star.loc[(x_17 == 1) & (x_18 ==1) & (x_19 ==1) & (x_20 == 1)].head()\n",
    "# h_x_star.drop('name',axis=1)\n",
    "# net_faill= h_x_star[(x_17 == 1) & (x_18 ==1) & (x_19 ==1) & (x_20 == 1)]\n",
    "# net_faill.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_x_star.loc[(x_17 == 1) & (x_18 ==1) & (x_19 ==1) & (x_20 == 1),'hx'] = 1  #label the failure network as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_x_star['hx'].fillna(0,inplace=True) #label the working network as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_x_star_plus = h_x_star['hx']  #extract the h_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, we calculate the importance sampling weight :\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "w\\left(\\overrightarrow{x_{i}^{*}}\\right)=\\frac{f\\left(\\overrightarrow{x_{i}^{*}}\\right)}{g\\left(\\overrightarrow{x_{i}^{*}}\\right)}=\\frac{p^{x_{i 1}^{*}}(1-p)^{1-x_{i 1}^{*}} p^{x_{i 2}^{*}}(1-p)^{1-x_{i 2}^{*}} \\ldots \\ldots p^{x_{i 20}^{*}}(1-p)^{1-x_{i 20}^{*}}}{p^{*} x_{i 1}^{*}\\left(1-p^{*}\\right)^{1-x_{i 1}^{*}} p^{*} x_{i 2}^{*}\\left(1-p^{*}\\right)^{1-x_{i 2}^{*}} \\ldots . . p^{* x_{i 20}^{*}\\left(1-p^{*}\\right)^{1-x_{i 20}^{*}}}} \\\\\n",
    "=\\frac{p^{\\sum_{i=1}^{i=20} x_{i j}}(1-p)^{20-\\sum_{i=1}^{i=20} x_{i j}^{*}}}{p^{*} \\sum_{i=1}^{i=20} x_{i j}\\left(1-p^{*}\\right)^{20-\\sum_{i=1}^{i=20} x_{i j}^{*}}}\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star = p ** n_faill * (1-p)**(n-n_faill) /(p_star ** n_faill * (1-p_star) ** (n-n_faill)) #importance sampling weight\n",
    "pd.DataFrame(w_star).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_fail_IS =  round(sum(w_star * h_x_star_plus)/N ,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the network failure probability is {P_fail_IS} by the Impotance sampling method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows us the probablity of netwok failure could be very small(on the other hand ,the reliability is very high), the bit error rate for many types signal transmission can range from $ 10 ^{-10} $ to $10^{-3}$ or even lower."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p9] *",
   "language": "python",
   "name": "conda-env-p9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "0142100476a55ad2707e4ee89bdff33f958300b25bb6983b2c86b093430e9fda"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
